#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
WD Tagger - Reference-style pipeline (config.json: size only, everything else same as reference)
- model.onnx / selected_tags.csv / config.json(ìˆìœ¼ë©´) ë¥¼ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œì— ì €ì¥/ì‚¬ìš©
- íŒŒì´í”„ë¼ì¸:
  * RGBA â†’ í°ìƒ‰ í•©ì„±
  * ë¹„ìœ¨ ìœ ì§€ íŒ¨ë”©(ì •ì‚¬ê°) â†’ target_sizeë¡œ ë¦¬ì‚¬ì´ì¦ˆ
  * RGB â†’ BGR (ì±„ë„ ìŠ¤ì™‘)
  * ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§ ì—†ìŒ (0~255 float)
  * NHWC (1,H,W,3) ì…ë ¥
  * ì¶œë ¥ê°’(preds)ì„ ê·¸ëŒ€ë¡œ confidenceë¡œ ì‚¬ìš© (sigmoid ë“± ì—†ìŒ)
  * rating=ì¹´í…Œê³ ë¦¬9(ì‚¬ì „ í˜•ì‹), general=0/character=4 ì„ê³„ê°’ ì»·
"""

import csv
import json
import os
import shutil
from pathlib import Path
from typing import List, Tuple, Optional, Dict

import numpy as np
from PIL import Image as PILImage
import onnxruntime as ort
import os
import huggingface_hub
import requests
from PySide6.QtCore import QObject, Signal, QThread

# â–¼ ì¶”ê°€: pip ê²½ë¡œ ì •í™• íƒìƒ‰ + DLL ê²€ìƒ‰ ê²½ë¡œ ì£¼ì…ìš©
import sys
import importlib.util


# ì „ì—­ ë‹¤ìš´ë¡œë“œ ì§„í–‰ ìƒí™© ì‹œê·¸ë„ (QObject ì¸ìŠ¤í„´ìŠ¤ í•„ìš”)
class DownloadProgressEmitter(QObject):
    progress_updated = Signal(str, int, int, str)  # filename, downloaded, total, status

download_progress_emitter = DownloadProgressEmitter()


def check_gpu_availability():
    """GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        # ONNX Runtimeì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ providers í™•ì¸
        available_providers = ort.get_available_providers()
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ providers: {available_providers}")
        
        if 'CUDAExecutionProvider' in available_providers:
            print("âœ… CUDA GPU ì‚¬ìš© ê°€ëŠ¥")
            return True
        else:
            print("âŒ CUDA GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥")
            return False
    except Exception as e:
        print(f"GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


MODEL_FILENAME = "model.onnx"
LABEL_FILENAME = "selected_tags.csv"  # ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©
CONFIG_CANDIDATES = ["config.json", "preprocessor_config.json"]
TAGGER_CONFIG_FILE = "models/wd_tagger_config.json"  # WD ì „ìš© ì„¤ì • íŒŒì¼

# ì¹´í…Œê³ ë¦¬ ì •ì˜(ë ˆí¼ëŸ°ìŠ¤ì™€ ë™ì¼)
RATING_CAT = 9
GENERAL_CAT = 0
CHAR_CAT = 4

# kaomojis(ì–¸ë”ìŠ¤ì½”ì–´ ìœ ì§€)
kaomojis = [
    "0_0","(o)_(o)","+_+","+_-","._.","<o>_<o>","<|>_<|>","=_=",
    ">_<","3_3","6_9",">_o","@_@","^_^","o_o","u_u","x_x","|_|","||_||",
]


def _script_dir() -> Path:
    return Path(__file__).resolve().parent


def _migrate_old_models():
    """ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ í´ë”ì— ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ë“¤ì„ ëª¨ë¸ë³„ í´ë”ë¡œ ì´ë™"""
    script_dir = _script_dir()
    
    # ê¸°ì¡´ íŒŒì¼ë“¤ í™•ì¸
    old_files = {
        "model.onnx": "wd-vit-large-tagger-v3",  # ê¸°ë³¸ ëª¨ë¸ë¡œ ê°€ì •
        "selected_tags.csv": "wd-vit-large-tagger-v3",
        "config.json": "wd-vit-large-tagger-v3",
        "preprocessor_config.json": "wd-vit-large-tagger-v3"
    }
    
    for filename, default_model in old_files.items():
        old_path = script_dir / filename
        if old_path.exists():
            # ëª¨ë¸ë³„ í´ë” ìƒì„±
            model_dir = script_dir / "models" / default_model
            model_dir.mkdir(parents=True, exist_ok=True)
            
            # ìƒˆ ê²½ë¡œ
            new_path = model_dir / filename
            
            # íŒŒì¼ ì´ë™
            if not new_path.exists():
                print(f"ëª¨ë¸ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜: {old_path} -> {new_path}")
                old_path.rename(new_path)
            else:
                print(f"ëª¨ë¸ íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {new_path}")
                old_path.unlink()  # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ


def _ensure_local_from_hub(repo_id: str, repo_filename: str, local_name: str, file_index: int = 1, total_files: int = 1) -> Path:
    """
    HF Hubì—ì„œ ë°›ì•„ì„œ ëª¨ë¸ë³„ í´ë”ì— 'ì‹¤ì œ íŒŒì¼'ë¡œ ë‘”ë‹¤(ì‹¬ë§í¬ X).
    ìºì‹œë¥¼ ì™„ì „íˆ ìš°íšŒí•˜ê³  ì§ì ‘ ë‹¤ìš´ë¡œë“œ.
    LLaVAì™€ í†µì¼ëœ ê³ ê¸‰ ê¸°ëŠ¥ í¬í•¨: íŒŒì¼ ê²€ì¦, ì´ì–´ë°›ê¸°, ì§„í–‰ë¥  í‘œì‹œ
    """
    # ëª¨ë¸ë³„ í´ë” ìƒì„± (repo_idì—ì„œ ëª¨ë¸ëª… ì¶”ì¶œ)
    model_name = repo_id.split('/')[-1]  # "SmilingWolf/wd-vit-large-tagger-v3" -> "wd-vit-large-tagger-v3"
    model_dir = _script_dir() / "models" / model_name
    model_dir.mkdir(parents=True, exist_ok=True)
    
    dst = model_dir / local_name
    
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ í¬ê¸° í™•ì¸ í›„ ì¬ì‚¬ìš© ë˜ëŠ” ì´ì–´ë°›ê¸° (LLaVAì™€ í†µì¼)
    if dst.is_file():
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸ì„ ìœ„í•´ HEAD ìš”ì²­ (ë¦¬ë‹¤ì´ë ‰íŠ¸ ì¶”ì  ì¶”ê°€)
            download_url = f"https://huggingface.co/{repo_id}/resolve/main/{repo_filename}"
            head_response = requests.head(download_url, allow_redirects=True, timeout=15)
            if head_response.status_code == 200:
                expected_size = int(head_response.headers.get('content-length', 0))
                actual_size = dst.stat().st_size
                
                if actual_size == expected_size and expected_size > 0:
                    print(f"ê¸°ì¡´ íŒŒì¼ ì‚¬ìš© (ì™„ì „í•¨): {dst}")
                    return dst
                elif expected_size > 0 and actual_size < expected_size:
                    print(f"íŒŒì¼ ë¶ˆì™„ì „, ì´ì–´ë°›ê¸°: {dst} ({actual_size}/{expected_size} bytes)")
                    # ë¶ˆì™„ì „í•œ íŒŒì¼ì€ ì‚­ì œí•˜ì§€ ì•Šê³  ì´ì–´ë°›ê¸°ìš©ìœ¼ë¡œ ìœ ì§€
                elif expected_size == 0:
                    print(f"ì„œë²„ì—ì„œ í¬ê¸° ì •ë³´ ì—†ìŒ, ê¸°ì¡´ íŒŒì¼ ìœ ì§€: {dst}")
                    return dst
                elif actual_size > expected_size:
                    print(f"íŒŒì¼ í¬ê¸° ì´ˆê³¼ (ì†ìƒ ê°€ëŠ¥ì„±), ì¬ë‹¤ìš´ë¡œë“œ: {dst}")
                    dst.unlink()
                else:
                    print(f"íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜, ì¬ë‹¤ìš´ë¡œë“œ: {dst}")
                    dst.unlink()
            else:
                print(f"íŒŒì¼ í™•ì¸ ì‹¤íŒ¨ (HTTP {head_response.status_code}), ì¬ë‹¤ìš´ë¡œë“œ: {dst}")
                dst.unlink()
        except Exception as e:
            print(f"íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜, ì¬ë‹¤ìš´ë¡œë“œ: {e}")
            dst.unlink()
    
    print(f"WD ë‹¤ìš´ë¡œë“œ ì‹œì‘: {repo_id}/{repo_filename}")
    try:
        # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì‹œê·¸ë„ (ê°„ì†Œí™”)
        try:
            download_progress_emitter.progress_updated.emit(repo_filename, 0, 0, f"[{file_index}/{total_files}]")
        except Exception:
            pass
        
        # ì§ì ‘ ë‹¤ìš´ë¡œë“œ URL ìƒì„±
        download_url = f"https://huggingface.co/{repo_id}/resolve/main/{repo_filename}"
        
        print(f"ë‹¤ìš´ë¡œë“œ URL: {download_url}")
        
        # ì´ì–´ë°›ê¸° ì§€ì›ì„ ìœ„í•œ íŒŒì¼ í¬ê¸° í™•ì¸
        actual_size = 0
        if dst.is_file():
            actual_size = dst.stat().st_size
            print(f"ê¸°ì¡´ íŒŒì¼ í¬ê¸°: {actual_size / (1024*1024):.1f} MB")
        
        # HTTP Range í—¤ë”ë¡œ ì´ì–´ë°›ê¸° ì‹œë„
        headers = {}
        if actual_size > 0:
            headers['Range'] = f'bytes={actual_size}-'
            print(f"ì´ì–´ë°›ê¸° ì‹œë„: {actual_size} bytesë¶€í„°")
        
        # requestsë¡œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ (Range í—¤ë” í¬í•¨)
        response = requests.get(download_url, stream=True, headers=headers)
        response.raise_for_status()
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        if response.status_code == 206:  # Partial Content (ì´ì–´ë°›ê¸° ì„±ê³µ)
            content_range = response.headers.get('content-range', '')
            if content_range:
                # Content-Range: bytes 200-1023/1024 í˜•íƒœì—ì„œ ì´ í¬ê¸° ì¶”ì¶œ
                total_size = int(content_range.split('/')[-1])
                print(f"ì´ì–´ë°›ê¸° ì„±ê³µ: {actual_size}/{total_size} bytes")
            else:
                # Content-Rangeê°€ ì—†ìœ¼ë©´ Content-Length + ê¸°ì¡´ í¬ê¸°
                total_size = actual_size + int(response.headers.get('content-length', 0))
                print(f"ì´ì–´ë°›ê¸° ì„±ê³µ (ì¶”ì •): {actual_size}/{total_size} bytes")
        else:  # 200 OK (ì²˜ìŒë¶€í„° ë‹¤ìš´ë¡œë“œ)
            total_size = int(response.headers.get('content-length', 0))
            print(f"ì²˜ìŒë¶€í„° ë‹¤ìš´ë¡œë“œ: {total_size / (1024*1024):.1f} MB")
            actual_size = 0  # ì²˜ìŒë¶€í„° ë°›ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ë¦¬ì…‹
        
        # íŒŒì¼ í¬ê¸° ì •ë³´ ì‹œê·¸ë„ (ê°„ì†Œí™”)
        try:
            download_progress_emitter.progress_updated.emit(
                repo_filename, 
                actual_size, 
                total_size,  # í•­ìƒ ë°”ì´íŠ¸ë¡œ í†µì¼
                f"[{file_index}/{total_files}]"
            )
        except Exception:
            pass
        
        # íŒŒì¼ ì €ì¥ (ì´ì–´ë°›ê¸° ì§€ì›)
        downloaded = actual_size
        next_emit = actual_size
        emit_step = 1024*1024 if total_size >= 1024*1024 else 100*1024  # 1MB ë˜ëŠ” 100KB
        
        # íŒŒì¼ ëª¨ë“œ ê²°ì • (ì´ì–´ë°›ê¸°ë©´ 'ab', ì²˜ìŒë¶€í„°ë©´ 'wb')
        file_mode = 'ab' if actual_size > 0 else 'wb'
        
        with open(dst, file_mode) as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ëˆ„ì  ì„ê³„ì¹˜ ë°©ì‹)
                    if total_size > 0 and (downloaded >= next_emit or downloaded == total_size):
                        try:
                            download_progress_emitter.progress_updated.emit(
                                repo_filename, 
                                downloaded,  # ë°”ì´íŠ¸ë¡œ í†µì¼
                                total_size,  # ë°”ì´íŠ¸ë¡œ í†µì¼
                                f"[{file_index}/{total_files}] {downloaded/(1024*1024):.1f}MB / {total_size/(1024*1024):.1f}MB"
                            )
                            next_emit = downloaded + emit_step
                        except Exception:
                            pass
        
        print(f'\në‹¤ìš´ë¡œë“œ ì™„ë£Œ: {dst}')
        
        # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ì‹œê·¸ë„
        try:
            download_progress_emitter.progress_updated.emit(
                repo_filename, 
                total_size, 
                total_size, 
                "ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!"
            )
        except Exception:
            pass
        
        return dst
        
    except Exception as e:
        print(f"ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("Hugging Face Hub ìºì‹œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
        
        # ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
        try:
            cached = huggingface_hub.hf_hub_download(
                repo_id, filename=repo_filename, local_dir=str(_script_dir()), local_dir_use_symlinks=False
            )
            cached_path = Path(cached)
            if cached_path.resolve() != dst.resolve():
                shutil.copy2(cached_path, dst)
            print(f"ìºì‹œ ë°©ì‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {dst}")
            return dst
        except Exception as e2:
            print(f"ìºì‹œ ë°©ì‹ë„ ì‹¤íŒ¨: {e2}")
            raise


def _maybe_local_config(repo_id: str) -> Optional[Path]:
    # ëª¨ë¸ë³„ í´ë” ê²½ë¡œ ìƒì„±
    model_name = repo_id.split('/')[-1]
    model_dir = _script_dir() / "models" / model_name
    
    # 1) ëª¨ë¸ë³„ í´ë”ì—ì„œ ìš°ì„  ê²€ìƒ‰
    for name in CONFIG_CANDIDATES:
        p = model_dir / name
        if p.is_file():
            return p
    
    # 2) í—ˆë¸Œì—ì„œ ì‹œë„ (ëª¨ë¸ë³„ í´ë”ì— ì €ì¥)
    for name in CONFIG_CANDIDATES:
        try:
            return _ensure_local_from_hub(repo_id, name, name)
        except Exception:
            continue
    return None


def _safe_int(x):
    try:
        return int(x)
    except Exception:
        return None


def load_tagger_config():
    """ì „ ëª¨ë¸ ê³µí†µ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = _script_dir() / TAGGER_CONFIG_FILE
    default_config = {
        "general_threshold": 0.35,
        "character_threshold": 0.85,
        "character_mcut_min": 0.15,
        "max_tags": 30,
        "general_mcut_enabled": False,
        "character_mcut_enabled": False,
        "general_mcut_min_enabled": False,
        "general_mcut_min": 0.15,
        "character_mcut_min_enabled": False,
        "apply_sigmoid": False,
        "tta_enabled": False,
        "tta_horizontal_flip": True,
        "tta_merge_mode": "mean"
    }
    
    try:
        if config_path.exists():
            with config_path.open("r", encoding="utf-8") as f:
                config = json.load(f)
                # ê¸°ë³¸ê°’ê³¼ ë³‘í•© (ëˆ„ë½ëœ í‚¤ê°€ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
                for key, default_value in default_config.items():
                    if key not in config:
                        config[key] = default_value
                return config
        else:
            # ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
            save_tagger_config(default_config)
            return default_config
    except Exception as e:
        print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return default_config


def save_tagger_config(config):
    """ì „ ëª¨ë¸ ê³µí†µ ì„¤ì • íŒŒì¼ ì €ì¥"""
    config_path = _script_dir() / TAGGER_CONFIG_FILE
    try:
        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"âœ… ì„¤ì • íŒŒì¼ ì €ì¥ ì™„ë£Œ: {config_path}")
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def get_tagger_config_value(key, default_value=None):
    """ì„¤ì • íŒŒì¼ì—ì„œ íŠ¹ì • ê°’ ê°€ì ¸ì˜¤ê¸°"""
    config = load_tagger_config()
    return config.get(key, default_value)


class WdTaggerModel(QObject):
    progress_updated = Signal(int, int)
    tag_generated = Signal(str, list)    # image_path, List[(tag, score)]
    finished = Signal()
    error_occurred = Signal(str)

    def __init__(
        self,
        model_id: str = "SmilingWolf/wd-vit-large-tagger-v3",
        general_threshold: float = None,
        character_threshold: float = None,
        pad_rgb=(255, 255, 255),
        use_gpu: bool = True,
    ):
        super().__init__()
        self.model_id = model_id
        # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
        self.general_threshold = general_threshold if general_threshold is not None else get_tagger_config_value("general_threshold", 0.35)
        self.character_threshold = character_threshold if character_threshold is not None else get_tagger_config_value("character_threshold", 0.85)
        self.pad_rgb = pad_rgb
        self.use_gpu = use_gpu

        self.session: Optional[ort.InferenceSession] = None
        self.is_loaded = False

        # íƒœê·¸/ì¸ë±ìŠ¤
        self.tag_names: List[str] = []
        self.rating_indexes: List[int] = []
        self.general_indexes: List[int] = []
        self.character_indexes: List[int] = []

        # configì—ì„œ ì½ì„ ê°’(í¬ê¸°ë§Œ ë°˜ì˜)
        self.target_size = 448  # ê¸°ë³¸ê°’
        
        # LLaVAì™€ í†µì¼ëœ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ìœ„í•œ ì†ì„±
        self.model_dir = None

        # â–¼ ì¶”ê°€: Windowsì—ì„œ add_dll_directory í•¸ë“¤ ìœ ì§€
        self._dll_dir_handles: List[object] = []

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLaVAì™€ í†µì¼ëœ ê³ ê¸‰ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def download_model_files(self):
        """WD ëª¨ë¸ íŒŒì¼ë“¤ ë‹¤ìš´ë¡œë“œ (LLaVAì™€ í†µì¼ëœ ê³ ê¸‰ ë°©ì‹)"""
        try:
            print(f"WD ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {self.model_id}")
            
            # WD ëª¨ë¸ì˜ í•„ìˆ˜ íŒŒì¼ë“¤ ì •ì˜
            required_files = ['model.onnx', 'selected_tags.csv', 'config.json']
            total_files = len(required_files)
            
            print(f"ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ ëª©ë¡ ({total_files}ê°œ):")
            for i, filename in enumerate(required_files):
                print(f"  {i+1}. {filename}")
            
            # ì „ì²´ ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì‹œê·¸ë„ (LLaVAì™€ ë™ì¼í•œ í˜•íƒœ - ê°„ì†Œí™”)
            try:
                download_progress_emitter.progress_updated.emit("WD ëª¨ë¸", 0, 0, f"[0/{total_files}]")
            except Exception:
                pass
            
            # ê° íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ (ëˆ„ë½ëœ íŒŒì¼ë§Œ)
            downloaded_count = 0
            for i, filename in enumerate(required_files):
                try:
                    # íŒŒì¼ì´ ì´ë¯¸ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    model_name = self.model_id.split('/')[-1]
                    model_dir = _script_dir() / "models" / model_name
                    self.model_dir = model_dir
                    dst = model_dir / filename
                    
                    if dst.exists():
                        try:
                            # íŒŒì¼ í¬ê¸° í™•ì¸
                            download_url = f"https://huggingface.co/{self.model_id}/resolve/main/{filename}"
                            head_response = requests.head(download_url)
                            if head_response.status_code == 200:
                                expected_size = int(head_response.headers.get('content-length', 0))
                                actual_size = dst.stat().st_size
                                
                                if actual_size == expected_size and expected_size > 0:
                                    print(f"íŒŒì¼ ì´ë¯¸ ì™„ì „í•¨ (ìŠ¤í‚µ): {filename} [{i+1}/{total_files}]")
                                    downloaded_count += 1
                                    continue
                        except Exception:
                            pass
                    
                    print(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {filename} [{i+1}/{total_files}]")
                    
                    # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì‹œê·¸ë„ (LLaVAì™€ ë™ì¼í•œ í˜•íƒœ)
                    try:
                        download_progress_emitter.progress_updated.emit(filename, 0, 0, f"[{i+1}/{total_files}]")
                    except Exception:
                        pass
                    
                    # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ (íŒŒì¼ ë²ˆí˜¸ ì •ë³´ ì „ë‹¬)
                    _ensure_local_from_hub(self.model_id, filename, filename, file_index=i+1, total_files=total_files)
                    
                    print(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename} [{i+1}/{total_files}]")
                    downloaded_count += 1
                    
                except Exception as e:
                    print(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ë¬´ì‹œ): {filename} [{i+1}/{total_files}] - {e}")
                    continue
            
            print(f"WD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {self.model_id}")
            
            # ì „ì²´ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ì‹œê·¸ë„ (LLaVAì™€ ë™ì¼í•œ í˜•íƒœ - ê°„ì†Œí™”)
            try:
                download_progress_emitter.progress_updated.emit("WD ëª¨ë¸", 0, 0, f"[{total_files}/{total_files}]")
            except Exception:
                pass
            
            return True
            
        except Exception as e:
            print(f"WD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def check_model_files(self) -> bool:
        """WD ëª¨ë¸ íŒŒì¼ë“¤ì´ ë¡œì»¬ì— ìˆëŠ”ì§€ í™•ì¸ (LLaVAì™€ í†µì¼)"""
        if not self.model_dir:
            model_name = self.model_id.split('/')[-1]
            self.model_dir = _script_dir() / "models" / model_name
        
        if not self.model_dir.exists():
            return False
        
        try:
            # í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸
            required_files = ['model.onnx', 'selected_tags.csv', 'config.json']
            
            # ê° íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            for filename in required_files:
                if not (self.model_dir / filename).exists():
                    print(f"í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {filename}")
                    return False
            
            print(f"ëª¨ë“  í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ í™•ì¸: {len(required_files)}ê°œ íŒŒì¼")
            return True
            
        except Exception as e:
            print(f"íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def get_model_info(self) -> dict:
        """WD ëª¨ë¸ ì •ë³´ ë°˜í™˜ (LLaVAì™€ í†µì¼)"""
        return {
            "model_id": self.model_id,
            "model_name": self.model_id.split('/')[-1],
            "is_downloaded": self.check_model_files(),
            "model_dir": str(self.model_dir) if self.model_dir else None,
            "use_gpu": self.use_gpu
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _load_tags(self, csv_path: Path):
        self.tag_names.clear()
        self.rating_indexes.clear()
        self.general_indexes.clear()
        self.character_indexes.clear()

        with csv_path.open("r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for i, row in enumerate(reader):
                name = row["name"]
                # kaomojisëŠ” ì–¸ë”ìŠ¤ì½”ì–´ ìœ ì§€, ê·¸ ì™¸ ì–¸ë”ìŠ¤ì½”ì–´â†’ìŠ¤í˜ì´ìŠ¤
                if name not in kaomojis:
                    name = name.replace("_", " ")
                self.tag_names.append(name)

                try:
                    cat = int(row.get("category", "0"))
                except Exception:
                    cat = 0

                if cat == RATING_CAT:
                    self.rating_indexes.append(i)
                elif cat == CHAR_CAT:
                    self.character_indexes.append(i)
                elif cat == GENERAL_CAT:
                    self.general_indexes.append(i)
                else:
                    # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” generalë¡œ ì·¨ê¸‰í•˜ì§€ ì•ŠìŒ (ë ˆí¼ëŸ°ìŠ¤ì™€ ë™ì¼ ë¶„ë¥˜)
                    pass

    def _maybe_read_config_for_size(self, cfg_path: Optional[Path]):
        """
        config.jsonì—ì„œ input_sizeë¥¼ ì½ì–´ target_sizeë§Œ ë°˜ì˜.
        (ì „ì²˜ë¦¬/ì •ê·œí™”/ë ˆì´ì•„ì›ƒ ë“±ì€ ëª¨ë‘ ë ˆí¼ëŸ°ìŠ¤ëŒ€ë¡œ ìœ ì§€)
        """
        if not cfg_path or not cfg_path.is_file():
            return
        try:
            with cfg_path.open("r", encoding="utf-8") as f:
                cfg = json.load(f)
            pcfg = cfg.get("pretrained_cfg", {})
            inp = pcfg.get("input_size", None)
            if isinstance(inp, list) and len(inp) == 3:
                # [3,H,W] or [H,W,3] â†’ ì •ì‚¬ê°ë§Œ ì“°ë¯€ë¡œ H ë˜ëŠ” W ì‚¬ìš©
                if inp[0] == 3:
                    self.target_size = _safe_int(inp[1]) or self.target_size
                elif inp[-1] == 3:
                    self.target_size = _safe_int(inp[0]) or self.target_size
        except Exception:
            pass

    # â–¼ ì¶”ê°€: DLL ê²€ìƒ‰ ê²½ë¡œ ì£¼ì… ìœ í‹¸
    def _add_dll_dir(self, p: str):
        try:
            if os.name == "nt":
                h = os.add_dll_directory(p)
                self._dll_dir_handles.append(h)
        except Exception:
            pass
        # PATHì—ë„ prepend (ë³´ì¡°)
        cur = os.environ.get("PATH", "")
        if p not in cur.split(";"):
            os.environ["PATH"] = p + ";" + cur

    def _inject_cuda_from_pip(self) -> List[str]:
        """
        pipë¡œ ì„¤ì¹˜ëœ nvidia-cu12 íŒ¨í‚¤ì§€ë“¤ì˜ bin/lib ê²½ë¡œë¥¼ importlibë¡œ ì°¾ì€ ë’¤
        DLL ê²€ìƒ‰ ê²½ë¡œì— ì£¼ì…í•œë‹¤.
        """
        found: List[str] = []
        modules = [
            "nvidia.cuda_runtime",
            "nvidia.cublas",
            "nvidia.cudnn",
            "nvidia.cufft",
            "nvidia.curand",
            "nvidia.cusolver",
            "nvidia.cusparse",
            "nvidia.nvjitlink",
        ]
        for m in modules:
            try:
                spec = importlib.util.find_spec(m)
                if not spec:
                    continue
                if spec.submodule_search_locations:
                    base = Path(list(spec.submodule_search_locations)[0])
                else:
                    base = Path(spec.origin).parent
                for sub in ("bin", "lib"):
                    cand = base / sub
                    if cand.is_dir():
                        p = str(cand.resolve())
                        self._add_dll_dir(p)
                        found.append(p)
                        break
            except Exception:
                continue
        return found

    def _inject_cuda_from_system(self) -> List[str]:
        """
        ì‹œìŠ¤í…œ CUDA(íˆ´í‚·) ê²½ë¡œë¥¼ DLL ê²€ìƒ‰ ê²½ë¡œì— ì£¼ì…. 12.x ìš°ì„ , 11.x í›„ìˆœìœ„.
        """
        added: List[str] = []
        candidates = []
        env_cuda = os.environ.get("CUDA_PATH")
        if env_cuda:
            candidates.append(env_cuda)
        candidates += [
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.5",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.2",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.0",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6",
        ]
        for base in candidates:
            bin_dir = os.path.join(base, "bin")
            if os.path.isdir(bin_dir):
                self._add_dll_dir(bin_dir)
                added.append(bin_dir)
        return added

    def _verify_cu12_presence(self) -> bool:
        """
        cu12 í•µì‹¬ DLL(cudart64_12.dll / cublasLt64_12.dll)ì´ PATHì—ì„œ ë³´ì´ëŠ”ì§€ ë¹ ë¥´ê²Œ ì ê²€.
        """
        targets = ("cudart64_12.dll", "cublasLt64_12.dll")
        for t in targets:
            for p in os.environ.get("PATH", "").split(";"):
                if p and os.path.isfile(os.path.join(p, t)):
                    return True
        return False

    def load_model(self):
        try:
            # ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜ (í•œ ë²ˆë§Œ ì‹¤í–‰)
            _migrate_old_models()
            
            # LLaVAì™€ í†µì¼ëœ ê³ ê¸‰ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©
            if not self.check_model_files():
                print(f"WD ëª¨ë¸ íŒŒì¼ì´ ëˆ„ë½ë¨, ê³ ê¸‰ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {self.model_id}")
                self.download_model_files()
            
            # ëª¨ë¸ë³„ í´ë”ì— ìì‚° í™•ë³´ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
            labels_path = _ensure_local_from_hub(self.model_id, LABEL_FILENAME, LABEL_FILENAME)
            model_path  = _ensure_local_from_hub(self.model_id, MODEL_FILENAME, MODEL_FILENAME)
            cfg_path    = _maybe_local_config(self.model_id)  # optional

            # íƒœê·¸ ë¡œë“œ
            self._load_tags(labels_path)

            # ONNX Runtime ìƒíƒœ í™•ì¸
            print(f"ğŸ” ONNX Runtime ìƒíƒœ í™•ì¸:")
            print(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ providers: {ort.get_available_providers()}")
            print(f"   - GPU ëª¨ë“œ ì„¤ì •: {self.use_gpu}")
            print(f"   - ëª¨ë¸ ê²½ë¡œ: {model_path}")

            # GPU ëª¨ë“œì¼ ë•Œ ë™ì ìœ¼ë¡œ NVIDIA íŒ¨í‚¤ì§€ ê²½ë¡œ ì°¾ê¸°
            if self.use_gpu:
                print("ğŸ”§ NVIDIA DLL ê²½ë¡œ íƒìƒ‰ ì‹œì‘")
                # 1) pipì—ì„œ cu12 ì»´í¬ë„ŒíŠ¸ ê²½ë¡œ ì£¼ì… (ê°€ì¥ ì‹ ë¢°)
                pip_paths = self._inject_cuda_from_pip()
                # 2) ì‹œìŠ¤í…œ CUDA ê²½ë¡œ ì£¼ì… (12.x ìš°ì„ )
                sys_paths = self._inject_cuda_from_system()

                # ì¶œë ¥ ì •ë¦¬
                all_added: List[str] = []
                all_added.extend(pip_paths)
                for p in sys_paths:
                    if p not in all_added:
                        all_added.append(p)

                if all_added:
                    print(f"ğŸ”§ NVIDIA DLL ê²½ë¡œ ì¶”ê°€: {len(all_added)}ê°œ ê²½ë¡œ")
                    for p in all_added:
                        print(f"   - {p}")
                else:
                    print("âš ï¸ NVIDIA DLL ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (pip nvidia-cu12 íŒ¨í‚¤ì§€ ë˜ëŠ” CUDA Toolkit 12.x í•„ìš”)")

                if not self._verify_cu12_presence():
                    print("â— cu12 í•µì‹¬ DLL(cudart64_12.dll ë“±)ì„ PATHì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. pip ë˜ëŠ” CUDA 12.x ì„¤ì¹˜/í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

            # ONNX ì„¸ì…˜ (GPU/CPU ëª¨ë“œ ì„ íƒ)
            if self.use_gpu:
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                print(f"ğŸš€ GPU ëª¨ë“œë¡œ ì„¸ì…˜ ìƒì„± ì‹œë„: {providers}")
                try:
                    self.session = ort.InferenceSession(str(model_path), providers=providers)
                    # ì‹¤ì œ ì‚¬ìš©ëœ provider í™•ì¸
                    actual_providers = self.session.get_providers()
                    print(f"GPU ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - ì‚¬ìš©ëœ providers: {actual_providers}")
                    if 'CUDAExecutionProvider' in actual_providers:
                        print("âœ… GPU (CUDA) ì‚¬ìš© ì¤‘")
                    else:
                        print("âš ï¸ GPU ì‚¬ìš© ì‹¤íŒ¨, CPUë¡œ ì‹¤í–‰ ì¤‘")
                except Exception as e:
                    # GPU ì‚¬ìš© ì‹¤íŒ¨ ì‹œ CPUë¡œ fallback
                    print(f"âŒ GPU ì‚¬ìš© ì‹¤íŒ¨, CPUë¡œ fallback: {e}")
                    self.session = ort.InferenceSession(str(model_path), providers=['CPUExecutionProvider'])
                    actual_providers = self.session.get_providers()
                    print(f"CPU ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - ì‚¬ìš©ëœ providers: {actual_providers}")
            else:
                print(f"ğŸ–¥ï¸ CPU ëª¨ë“œë¡œ ì„¸ì…˜ ìƒì„±")
                self.session = ort.InferenceSession(str(model_path), providers=['CPUExecutionProvider'])
                actual_providers = self.session.get_providers()
                print(f"CPU ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - ì‚¬ìš©ëœ providers: {actual_providers}")

            # configì—ì„œ target_sizeë§Œ ìš°ì„  ë°˜ì˜
            self._maybe_read_config_for_size(cfg_path)

            # ê·¸ë˜ë„ target_sizeê°€ ì—†ìœ¼ë©´, ì…ë ¥ shapeì—ì„œ NHWCë¡œ ê°€ì •í•´ ë†’ì´ ì‚¬ìš©(ë ˆí¼ëŸ°ìŠ¤ì™€ ë™ì¼ íë¦„)
            try:
                _, height, width, _ = self.session.get_inputs()[0].shape  # NHWC ê°€ì •
                if isinstance(height, int) and height:
                    self.target_size = height
            except Exception:
                pass

            self.is_loaded = True

        except Exception as e:
            self.error_occurred.emit(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì „ì²˜ë¦¬(ë ˆí¼ëŸ°ìŠ¤ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _alpha_composite_rgb(self, image: PILImage.Image, bg_rgb=(255, 255, 255)) -> PILImage.Image:
        if image.mode == "RGBA":
            bg = PILImage.new("RGBA", image.size, bg_rgb + (255,))
            return PILImage.alpha_composite(bg, image).convert("RGB")
        return image.convert("RGB")

    def _prepare_tensor_reference(self, pil_img: PILImage.Image) -> np.ndarray:
        """
        ë ˆí¼ëŸ°ìŠ¤ íŒŒì´í”„ë¼ì¸:
          - RGBA â†’ í°ìƒ‰ í•©ì„±
          - ë¹„ìœ¨ ìœ ì§€ íŒ¨ë”©(ì •ì‚¬ê°) â†’ target_size ë¦¬ì‚¬ì´ì¦ˆ
          - RGB â†’ BGR
          - float32 (0~255), ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§ ì—†ìŒ
          - NHWC (1,H,W,3)
        """
        img = self._alpha_composite_rgb(pil_img, bg_rgb=self.pad_rgb)

        target = int(self.target_size) if self.target_size else 448
        w, h = img.size
        max_dim = max(w, h)
        pad_left = (max_dim - w) // 2
        pad_top = (max_dim - h) // 2

        padded = PILImage.new("RGB", (max_dim, max_dim), self.pad_rgb)
        padded.paste(img, (pad_left, pad_top))

        if max_dim != target:
            padded = padded.resize((target, target), PILImage.BICUBIC)

        arr = np.asarray(padded, dtype=np.float32)  # 0~255 float
        arr = arr[:, :, ::-1]  # RGB â†’ BGR
        arr = np.expand_dims(arr, axis=0)  # NHWC
        return arr

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶”ë¡ /í›„ì²˜ë¦¬(ë ˆí¼ëŸ°ìŠ¤ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _mcut_threshold(self, probs: np.ndarray) -> float:
        """MCut (ì˜µì…˜)"""
        sorted_probs = probs[np.argsort(probs)[::-1]]
        difs = sorted_probs[:-1] - sorted_probs[1:]
        t = np.argmax(difs)
        return float((sorted_probs[t] + sorted_probs[t + 1]) / 2.0)

    def predict_tags(
        self,
        image_path: str,
        general_mcut_enabled: bool = None,
        character_mcut_enabled: bool = None,
        max_tags: int = None,
        exclude_tags: Optional[List[str]] = None,
    ) -> List[Tuple[str, float]]:
        """
        ë ˆí¼ëŸ°ìŠ¤ ë¡œì§ìœ¼ë¡œ íƒœê·¸ ì„ íƒ í›„ (general+character) í•©ì³ ì ìˆ˜ìˆœ ë°˜í™˜.
        rating(ì¹´í…Œê³ ë¦¬9)ì€ ë‚´ë¶€ì—ì„œ dictë¡œ ê³„ì‚°í•˜ì§€ë§Œ ë°˜í™˜ ëª©ë¡ì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ(ë ˆí¼ëŸ°ìŠ¤ UI í˜¸í™˜).
        """
        if not self.is_loaded:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
        if max_tags is None:
            max_tags = get_tagger_config_value("max_tags", 30)
        if general_mcut_enabled is None:
            general_mcut_enabled = get_tagger_config_value("general_mcut_enabled", False)
        if character_mcut_enabled is None:
            character_mcut_enabled = get_tagger_config_value("character_mcut_enabled", False)
            
        try:
            import time
            start_time = time.time()
            
            pil = PILImage.open(image_path)
            tensor = self._prepare_tensor_reference(pil)

            input_name = self.session.get_inputs()[0].name
            out_name = self.session.get_outputs()[0].name
            
            # ì¶”ë¡  ì‹¤í–‰ ë° ì‹œê°„ ì¸¡ì •
            inference_start = time.time()
            preds = self.session.run([out_name], {input_name: tensor})[0]  # (1, num_tags)
            inference_time = time.time() - inference_start
            
            scores = preds[0].astype(np.float32)  # ê·¸ëŒ€ë¡œ confidence
            
            # ì‚¬ìš©ëœ provider í™•ì¸
            actual_providers = self.session.get_providers()
            provider_info = "GPU" if 'CUDAExecutionProvider' in actual_providers else "CPU"
            print(f"ğŸ” ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ ({provider_info} ëª¨ë“œ)")

            # (ì´ ë¶€ë¶„ì€ ë ˆí¼ëŸ°ìŠ¤ì˜ grouping/threshold ì ˆì°¨ì™€ ë™ì¼)
            labels = list(zip(self.tag_names, scores))

            rating_names = [labels[i] for i in self.rating_indexes]  # dictë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŒ
            rating_dict: Dict[str, float] = dict(rating_names)       # í•„ìš”ì‹œ ì‚¬ìš©

            general_names = [labels[i] for i in self.general_indexes]
            if general_mcut_enabled and len(general_names) >= 2:
                general_probs = np.array([x[1] for x in general_names], dtype=np.float32)
                general_mcut_min_enabled = get_tagger_config_value("general_mcut_min_enabled", False)
                if general_mcut_min_enabled:
                    general_mcut_min = get_tagger_config_value("general_mcut_min", 0.15)
                    general_thresh = max(general_mcut_min, self._mcut_threshold(general_probs))
                else:
                    general_thresh = self._mcut_threshold(general_probs)
            else:
                general_thresh = self.general_threshold
            general_res = {t: float(s) for (t, s) in general_names if s > general_thresh}

            character_names = [labels[i] for i in self.character_indexes]
            if character_mcut_enabled and len(character_names) >= 2:
                character_probs = np.array([x[1] for x in character_names], dtype=np.float32)
                character_mcut_min_enabled = get_tagger_config_value("character_mcut_min_enabled", False)
                if character_mcut_min_enabled:
                    character_mcut_min = get_tagger_config_value("character_mcut_min", 0.15)
                    character_thresh = max(character_mcut_min, self._mcut_threshold(character_probs))
                else:
                    character_thresh = self._mcut_threshold(character_probs)
            else:
                character_thresh = self.character_threshold
            character_res = {t: float(s) for (t, s) in character_names if s > character_thresh}

            # ë°˜í™˜ í˜•ì‹: general+characterë¥¼ í•©ì³ ì ìˆ˜ìˆœ ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ì‹œê·¸ë„ í˜¸í™˜)
            ex = set(exclude_tags or [])
            picked = [(t, sc) for (t, sc) in {**general_res, **character_res}.items() if t not in ex]
            picked.sort(key=lambda x: x[1], reverse=True)
            if max_tags > 0:
                picked = picked[:max_tags]
            return picked

        except Exception as e:
            raise RuntimeError(f"íƒœê·¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

    def batch_predict(
        self,
        image_paths: List[str],
        general_mcut_enabled: bool = None,
        character_mcut_enabled: bool = None,
        max_tags: int = None,
        exclude_tags: Optional[List[str]] = None,
    ):
        if not self.is_loaded:
            self.load_model()
        
        # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
        if max_tags is None:
            max_tags = get_tagger_config_value("max_tags", 30)
        if general_mcut_enabled is None:
            general_mcut_enabled = get_tagger_config_value("general_mcut_enabled", False)
        if character_mcut_enabled is None:
            character_mcut_enabled = get_tagger_config_value("character_mcut_enabled", False)
            
        total = len(image_paths)
        
        # íƒœê·¸ ê²°ê³¼ ìˆ˜ì§‘
        tag_results = []
        
        for i, p in enumerate(image_paths):
            try:
                tags = self.predict_tags(
                    p,
                    general_mcut_enabled=general_mcut_enabled,
                    character_mcut_enabled=character_mcut_enabled,
                    max_tags=max_tags,
                    exclude_tags=exclude_tags,
                )
                tag_results.append(tags)
                self.tag_generated.emit(p, tags)
            except Exception as e:
                self.error_occurred.emit(f"ì´ë¯¸ì§€ {p} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                tag_results.append([])  # ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸
            finally:
                self.progress_updated.emit(i + 1, total)
        
        # íƒ€ì„ë¨¸ì‹  ë¡œê·¸ ê¸°ë¡ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
        try:
            from timemachine_log import log_ai_batch_tagging
            log_ai_batch_tagging("WD Tagger", self.model_id, image_paths, tag_results)
        except Exception:
            pass
        
        self.finished.emit()

    def batch_predict_unified(
        self,
        image_paths: List[str],
        mode: str = "auto",  # "v0", "v1", "v2", "auto"
        general_mcut_enabled: bool = None,
        character_mcut_enabled: bool = None,
        max_tags: int = None,
        exclude_tags: Optional[List[str]] = None,
    ):
        """
        í†µí•© ë°°ì¹˜ ì˜ˆì¸¡ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (WdTaggerModelìš©)
        - mode="auto": ì„¤ì •ì— ë”°ë¼ ìë™ìœ¼ë¡œ v0/v1/v2 ì„ íƒ
        - mode="v0": ê¸°ë³¸ ë©”ì„œë“œ ì‚¬ìš©
        - mode="v1": Enhanced V1 ì‚¬ìš© (Sigmoid + TTA)
        - mode="v2": Enhanced V2 ì‚¬ìš© (V1 + ì¼ë°˜ MCut min)
        """
        if not self.is_loaded:
            self.load_model()
        
        # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
        if max_tags is None:
            max_tags = get_tagger_config_value("max_tags", 30)
        if general_mcut_enabled is None:
            general_mcut_enabled = get_tagger_config_value("general_mcut_enabled", False)
        if character_mcut_enabled is None:
            character_mcut_enabled = get_tagger_config_value("character_mcut_enabled", False)
        
        # ì„±ëŠ¥ ê°€ë“œë ˆì¼: ëŒ€ëŸ‰ ë°°ì¹˜ ì‹œ TTA ë¹„í™œì„±í™”
        perf_tier = get_tagger_config_value("perf_tier", "balanced")  # "speed", "balanced", "quality"
        if perf_tier == "speed" and len(image_paths) > 10:
            print("âš ï¸ ì„±ëŠ¥ ìš°ì„  ëª¨ë“œ: ëŒ€ëŸ‰ ë°°ì¹˜ë¡œ ì¸í•´ TTA ë¹„í™œì„±í™”")
            # TTA ê°•ì œ ë¹„í™œì„±í™”ë¥¼ ìœ„í•œ ì„ì‹œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
            tta_enabled = False
        else:
            tta_enabled = get_tagger_config_value("tta_enabled", False)
        
        # auto ëª¨ë“œì—ì„œ ë²„ì „ ìë™ ì„ íƒ
        if mode == "auto":
            if tta_enabled and get_tagger_config_value("apply_sigmoid", False):
                mode = "v2"  # ê°€ì¥ ê³ ê¸‰ ê¸°ëŠ¥
            elif tta_enabled or get_tagger_config_value("apply_sigmoid", False):
                mode = "v1"  # ì¤‘ê°„ ê¸°ëŠ¥
            else:
                mode = "v0"  # ê¸°ë³¸ ê¸°ëŠ¥
        
        # ë¡œê¹… ì •ë³´
        log_info = {
            "mode": mode,
            "images": len(image_paths),
            "max_tags": max_tags,
            "general_mcut": general_mcut_enabled,
            "character_mcut": character_mcut_enabled,
            "perf_tier": perf_tier
        }
        
        # ë¡œê¹… ì •ë³´ ì¶œë ¥
        print(f"ğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ì‹œì‘: {log_info}")
        
        # ë²„ì „ë³„ ë©”ì„œë“œ í˜¸ì¶œ
        if mode == "v2" and hasattr(self, 'batch_predict_enhanced_v2'):
            print("âœ… V2 Enhanced methods ì‚¬ìš©")
            log_info["tta_applied"] = tta_enabled
            log_info["sigmoid_applied"] = get_tagger_config_value("apply_sigmoid", False)
            self.batch_predict_enhanced_v2(
                image_paths,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
        elif mode == "v1" and hasattr(self, 'batch_predict_enhanced'):
            print("âœ… V1 Enhanced methods ì‚¬ìš©")
            log_info["tta_applied"] = tta_enabled
            log_info["sigmoid_applied"] = get_tagger_config_value("apply_sigmoid", False)
            self.batch_predict_enhanced(
                image_paths,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
        else:
            print("âœ… ê¸°ë³¸ methods ì‚¬ìš©")
            log_info["tta_applied"] = False
            log_info["sigmoid_applied"] = False
            self.batch_predict(
                image_paths,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
        
        # ìµœì¢… ë¡œê¹… ì •ë³´ ì¶œë ¥
        print(f"ğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ: {log_info}")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_global_tagger = None

def get_global_tagger(
    model_id: str = "SmilingWolf/wd-vit-large-tagger-v3",
    general_threshold: float = None,
    character_threshold: float = None,
    pad_rgb=(255, 255, 255),
    use_gpu: bool = True,
):
    global _global_tagger
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
    if general_threshold is None:
        general_threshold = get_tagger_config_value("general_threshold", 0.35)
    if character_threshold is None:
        character_threshold = get_tagger_config_value("character_threshold", 0.85)
    
    # íŒŒë¼ë¯¸í„°ê°€ ë°”ë€Œë©´ ìƒˆë¡œ ìƒì„±
    if (_global_tagger is None or
        _global_tagger.model_id != model_id or
        _global_tagger.general_threshold != general_threshold or
        _global_tagger.character_threshold != character_threshold or
        _global_tagger.pad_rgb != pad_rgb or
        _global_tagger.use_gpu != use_gpu):
        print(f"ğŸ”„ ëª¨ë¸ ìƒˆë¡œ ë¡œë“œ: GPU={use_gpu}, Model={model_id}")
        _global_tagger = WdTaggerModel(
            model_id=model_id,
            general_threshold=general_threshold,
            character_threshold=character_threshold,
            pad_rgb=pad_rgb,
            use_gpu=use_gpu,
        )
        _global_tagger.load_model()
    else:
        print(f"â™»ï¸ ê¸°ì¡´ ëª¨ë¸ ì¬ì‚¬ìš©: GPU={_global_tagger.use_gpu}, Model={_global_tagger.model_id}")
    return _global_tagger


def get_tag_category(tag_name: str) -> str:
    """íƒœê·¸ì˜ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜ (general/character/rating)"""
    global _global_tagger
    if _global_tagger is None or not _global_tagger.is_loaded:
        return "unknown"
    
    try:
        # íƒœê·¸ ì´ë¦„ìœ¼ë¡œ ì¸ë±ìŠ¤ ì°¾ê¸°
        if tag_name in _global_tagger.tag_names:
            tag_index = _global_tagger.tag_names.index(tag_name)
            
            # ì¹´í…Œê³ ë¦¬ í™•ì¸
            if tag_index in _global_tagger.general_indexes:
                return "general"
            elif tag_index in _global_tagger.character_indexes:
                return "character"
            elif tag_index in _global_tagger.rating_indexes:
                return "rating"
            else:
                return "unknown"
        else:
            return "unknown"
    except Exception as e:
        print(f"íƒœê·¸ ì¹´í…Œê³ ë¦¬ í™•ì¸ ì˜¤ë¥˜: {e}")
        return "unknown"


class WdTaggerThread(QThread):
    progress_updated = Signal(int, int)
    tag_generated = Signal(str, list)
    finished = Signal()
    error_occurred = Signal(str)

    def __init__(
        self,
        image_paths: List[str],
        model_id: str = "SmilingWolf/wd-vit-large-tagger-v3",
        general_threshold: float = None,
        character_threshold: float = None,
        max_tags: int = None,
        pad_rgb=(255, 255, 255),
        exclude_tags: Optional[List[str]] = None,
        general_mcut_enabled: bool = None,
        character_mcut_enabled: bool = None,
        use_gpu: bool = True,
    ):
        super().__init__()
        self.image_paths = image_paths
        self.model_id = model_id
        self.general_threshold = general_threshold
        self.character_threshold = character_threshold
        self.max_tags = max_tags
        self.pad_rgb = pad_rgb
        self.exclude_tags = exclude_tags or []
        self.general_mcut_enabled = general_mcut_enabled
        self.character_mcut_enabled = character_mcut_enabled
        self.use_gpu = use_gpu
        self.tagger = None

    def run(self):
        try:
            # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
            general_threshold = self.general_threshold if self.general_threshold is not None else get_tagger_config_value("general_threshold", 0.35)
            character_threshold = self.character_threshold if self.character_threshold is not None else get_tagger_config_value("character_threshold", 0.85)
            max_tags = self.max_tags if self.max_tags is not None else get_tagger_config_value("max_tags", 30)
            general_mcut_enabled = self.general_mcut_enabled if self.general_mcut_enabled is not None else get_tagger_config_value("general_mcut_enabled", False)
            character_mcut_enabled = self.character_mcut_enabled if self.character_mcut_enabled is not None else get_tagger_config_value("character_mcut_enabled", False)
            
            self.tagger = get_global_tagger(
                model_id=self.model_id,
                general_threshold=general_threshold,
                character_threshold=character_threshold,
                pad_rgb=self.pad_rgb,
                use_gpu=self.use_gpu,
            )
            self.tagger.progress_updated.connect(self.progress_updated)
            self.tagger.tag_generated.connect(self.tag_generated)
            self.tagger.finished.connect(self.finished)
            self.tagger.error_occurred.connect(self.error_occurred)
            # í†µí•© ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ ì‚¬ìš© (auto ëª¨ë“œë¡œ ì„¤ì •ì— ë”°ë¼ ìë™ ì„ íƒ)
            self.tagger.batch_predict_unified(
                self.image_paths,
                mode="auto",  # ì„¤ì •ì— ë”°ë¼ v0/v1/v2 ìë™ ì„ íƒ
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=self.exclude_tags,
            )
        except Exception as e:
            self.error_occurred.emit(f"WD Tagger ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            self.finished.emit()

    def batch_predict_unified(
        self,
        image_paths: List[str],
        mode: str = "auto",  # "v0", "v1", "v2", "auto"
        general_mcut_enabled: bool = None,
        character_mcut_enabled: bool = None,
        max_tags: int = None,
        exclude_tags: Optional[List[str]] = None,
    ):
        """
        í†µí•© ë°°ì¹˜ ì˜ˆì¸¡ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
        - mode="auto": ì„¤ì •ì— ë”°ë¼ ìë™ìœ¼ë¡œ v0/v1/v2 ì„ íƒ
        - mode="v0": ê¸°ë³¸ ë©”ì„œë“œ ì‚¬ìš©
        - mode="v1": Enhanced V1 ì‚¬ìš© (Sigmoid + TTA)
        - mode="v2": Enhanced V2 ì‚¬ìš© (V1 + ì¼ë°˜ MCut min)
        """
        if not self.is_loaded:
            self.load_model()
        
        # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
        if max_tags is None:
            max_tags = get_tagger_config_value("max_tags", 30)
        if general_mcut_enabled is None:
            general_mcut_enabled = get_tagger_config_value("general_mcut_enabled", False)
        if character_mcut_enabled is None:
            character_mcut_enabled = get_tagger_config_value("character_mcut_enabled", False)
        
        # ì„±ëŠ¥ ê°€ë“œë ˆì¼: ëŒ€ëŸ‰ ë°°ì¹˜ ì‹œ TTA ë¹„í™œì„±í™”
        perf_tier = get_tagger_config_value("perf_tier", "balanced")  # "speed", "balanced", "quality"
        if perf_tier == "speed" and len(image_paths) > 10:
            print("âš ï¸ ì„±ëŠ¥ ìš°ì„  ëª¨ë“œ: ëŒ€ëŸ‰ ë°°ì¹˜ë¡œ ì¸í•´ TTA ë¹„í™œì„±í™”")
            # TTA ê°•ì œ ë¹„í™œì„±í™”ë¥¼ ìœ„í•œ ì„ì‹œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
            tta_enabled = False
        else:
            tta_enabled = get_tagger_config_value("tta_enabled", False)
        
        # auto ëª¨ë“œì—ì„œ ë²„ì „ ìë™ ì„ íƒ
        if mode == "auto":
            # V2 ì¡°ê±´: ì¼ë°˜ MCut minì´ í™œì„±í™”ë˜ì–´ ìˆê±°ë‚˜ í•„ìš”
            general_mcut_min_enabled = get_tagger_config_value("general_mcut_min_enabled", False)
            if general_mcut_min_enabled:
                mode = "v2"
                print("âœ… Auto mode: V2 ì„ íƒ (ì¼ë°˜ MCut min í™œì„±í™”)")
            else:
                # V1 ì¡°ê±´: Sigmoid ë˜ëŠ” TTAê°€ í™œì„±í™”
                apply_sigmoid = get_tagger_config_value("apply_sigmoid", False)
                if apply_sigmoid or tta_enabled:
                    mode = "v1"
                    print("âœ… Auto mode: V1 ì„ íƒ (Sigmoid/TTA í™œì„±í™”)")
                else:
                    mode = "v0"
                    print("âœ… Auto mode: V0 ì„ íƒ (ê¸°ë³¸ ì„¤ì •)")
        
        # ë¡œê¹… ì •ë³´ ìˆ˜ì§‘
        log_info = {
            "method_used": mode,
            "image_count": len(image_paths),
            "perf_tier": perf_tier,
            "general_mcut_enabled": general_mcut_enabled,
            "character_mcut_enabled": character_mcut_enabled,
            "max_tags": max_tags
        }
        
        # ë¡œê¹… ì •ë³´ ì¶œë ¥
        print(f"ğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ì‹œì‘: {log_info}")
        
        # ë²„ì „ë³„ ë©”ì„œë“œ í˜¸ì¶œ
        if mode == "v2" and hasattr(self, 'batch_predict_enhanced_v2'):
            print("âœ… V2 Enhanced methods ì‚¬ìš©")
            log_info["tta_applied"] = tta_enabled
            log_info["sigmoid_applied"] = get_tagger_config_value("apply_sigmoid", False)
            self.batch_predict_enhanced_v2(
                image_paths,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
        elif mode == "v1" and hasattr(self, 'batch_predict_enhanced'):
            print("âœ… V1 Enhanced methods ì‚¬ìš©")
            log_info["tta_applied"] = tta_enabled
            log_info["sigmoid_applied"] = get_tagger_config_value("apply_sigmoid", False)
            self.batch_predict_enhanced(
                image_paths,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
        else:
            print("âœ… ê¸°ë³¸ methods ì‚¬ìš©")
            log_info["tta_applied"] = False
            log_info["sigmoid_applied"] = False
            self.batch_predict(
                image_paths,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
        
        # ìµœì¢… ë¡œê¹… ì •ë³´ ì¶œë ¥
        print(f"ğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ: {log_info}")

# ============================================================================
# [ADDED] Enhancements: Sigmoid + TTA + JSON toggles (non-invasive additions)
# - No existing code above is modified; this block only adds new helpers/methods.
# - You can enable/disable via models/wd_tagger_config.json (keys documented below).
# ============================================================================

import numpy as _np
from PIL import Image as _PILImage

# ---- Config helpers (do NOT modify existing load/save; extend on top) ----

def _enh_default_config():
    return {
        "general_mcut_enabled": False,
        "character_mcut_enabled": False,
        "apply_sigmoid": False,
        "tta_enabled": False,
        "tta_horizontal_flip": True,
        "tta_merge_mode": "mean"  # "mean" or "max"
    }

def _load_enh_config_with_defaults():
    cfg = {}
    try:
        cfg = load_tagger_config()
    except Exception:
        cfg = {}
    # merge defaults without touching disk
    defaults = _enh_default_config()
    for k, v in defaults.items():
        cfg.setdefault(k, v)
    return cfg

def upgrade_tagger_config_for_enhancements():
    """
    Idempotent upgrade: ensure the new keys exist in models/wd_tagger_config.json.
    We do NOT touch existing values; only fill missing keys with defaults.
    """
    try:
        cfg = load_tagger_config()
        changed = False
        for k, v in _enh_default_config().items():
            if k not in cfg:
                cfg[k] = v
                changed = True
        if changed:
            save_tagger_config(cfg)
            print("ğŸ”§ wd_tagger_config.json upgraded with enhancement keys.")
    except Exception as e:
        print(f"âš ï¸ Could not upgrade wd_tagger_config.json: {e}")

# run upgrade at import-time (safe, only fills missing keys)
try:
    upgrade_tagger_config_for_enhancements()
except Exception:
    pass

# ---- Math helpers ----

def _safe_sigmoid(x: "_np.ndarray") -> "_np.ndarray":
    # stable sigmoid
    x = _np.clip(x, -60.0, 60.0)
    return 1.0 / (1.0 + _np.exp(-x))

def _merge_scores(arrs: "_np.ndarray", mode: str = "mean") -> "_np.ndarray":
    if mode == "max":
        return _np.max(arrs, axis=0)
    # default: mean
    return _np.mean(arrs, axis=0)

def _pil_horizontal_flip(img: "_PILImage") -> "_PILImage":
    try:
        return img.transpose(_PILImage.FLIP_LEFT_RIGHT)
    except Exception:
        arr = _np.array(img)
        return _PILImage.fromarray(arr[:, ::-1, ...])

# ---- WdTaggerModel: add NON-INTRUSIVE new methods (monkey-patched) ----

def _predict_scores_single_pass(self, pil_img, apply_sigmoid=False):
    """
    Internal single-pass inference that mirrors the reference pipeline,
    with optional sigmoid application.
    """
    tensor = self._prepare_tensor_reference(pil_img)
    input_name = self.session.get_inputs()[0].name
    out_name = self.session.get_outputs()[0].name
    preds = self.session.run([out_name], {input_name: tensor})[0]  # (1, num_tags)
    scores = preds[0].astype(_np.float32)  # baseline: as-is (reference behavior)
    if apply_sigmoid:
        scores = _safe_sigmoid(scores)
    return scores  # 1D (num_tags,)

def predict_tags_enhanced(
    self,
    image_path: str,
    use_config: bool = True,
    # Explicit overrides; if None, values come from JSON
    general_mcut_enabled: bool = None,
    character_mcut_enabled: bool = None,
    apply_sigmoid: bool = None,
    tta_enabled: bool = None,
    tta_horizontal_flip: bool = None,
    tta_merge_mode: str = None,
    max_tags: int = None,
    exclude_tags: list = None,
):
    """
    Enhanced prediction:
    - Optional sigmoid on raw outputs.
    - Optional TTA (currently: horizontal flip) with mean/max merge.
    - Thresholding identical to reference (including MCut when enabled).
    NOTE: This is an additive API; existing methods remain untouched.
    """
    if not self.is_loaded:
        self.load_model()

    # Resolve defaults
    cfg = _load_enh_config_with_defaults() if use_config else _enh_default_config()
    if general_mcut_enabled is None:
        general_mcut_enabled = bool(cfg.get("general_mcut_enabled", False))
    if character_mcut_enabled is None:
        character_mcut_enabled = bool(cfg.get("character_mcut_enabled", False))
    if apply_sigmoid is None:
        apply_sigmoid = bool(cfg.get("apply_sigmoid", False))
    if tta_enabled is None:
        tta_enabled = bool(cfg.get("tta_enabled", False))
    if tta_horizontal_flip is None:
        tta_horizontal_flip = bool(cfg.get("tta_horizontal_flip", True))
    if tta_merge_mode is None:
        tta_merge_mode = str(cfg.get("tta_merge_mode", "mean"))
    if max_tags is None:
        max_tags = get_tagger_config_value("max_tags", 30)

    # Load image
    pil = _PILImage.open(image_path)

    # Inference (single or TTA)
    if not tta_enabled:
        scores = _predict_scores_single_pass(self, pil, apply_sigmoid=apply_sigmoid)
    else:
        _scores = []
        # original
        _scores.append(_predict_scores_single_pass(self, pil, apply_sigmoid=apply_sigmoid))
        # horizontal flip (optional)
        if tta_horizontal_flip:
            pil_flip = _pil_horizontal_flip(pil)
            _scores.append(_predict_scores_single_pass(self, pil_flip, apply_sigmoid=apply_sigmoid))
        scores = _merge_scores(_np.stack(_scores, axis=0), mode=tta_merge_mode).astype(_np.float32)

    # Thresholding (exactly as in reference predict_tags)
    labels = list(zip(self.tag_names, scores))

    # rating kept for internal parity; not returned
    rating_names = [labels[i] for i in self.rating_indexes]
    _ = dict(rating_names)

    # general
    general_names = [labels[i] for i in self.general_indexes]
    if general_mcut_enabled and len(general_names) >= 2:
        general_probs = _np.array([x[1] for x in general_names], dtype=_np.float32)
        general_thresh = self._mcut_threshold(general_probs)
    else:
        general_thresh = self.general_threshold
    general_res = {t: float(s) for (t, s) in general_names if s > general_thresh}

    # character (with floor via character_mcut_min when MCut is used)
    character_names = [labels[i] for i in self.character_indexes]
    if character_mcut_enabled and len(character_names) >= 2:
        character_probs = _np.array([x[1] for x in character_names], dtype=_np.float32)
        character_mcut_min = get_tagger_config_value("character_mcut_min", 0.15)
        character_thresh = max(character_mcut_min, self._mcut_threshold(character_probs))
    else:
        character_thresh = self.character_threshold
    character_res = {t: float(s) for (t, s) in character_names if s > character_thresh}

    ex = set(exclude_tags or [])
    picked = [(t, sc) for (t, sc) in {**general_res, **character_res}.items() if t not in ex]
    picked.sort(key=lambda x: x[1], reverse=True)
    if max_tags > 0:
        picked = picked[:max_tags]
    return picked

def batch_predict_enhanced(
    self,
    image_paths,
    use_config: bool = True,
    general_mcut_enabled: bool = None,
    character_mcut_enabled: bool = None,
    apply_sigmoid: bool = None,
    tta_enabled: bool = None,
    tta_horizontal_flip: bool = None,
    tta_merge_mode: str = None,
    max_tags: int = None,
    exclude_tags=None,
):
    if not self.is_loaded:
        self.load_model()

    if max_tags is None:
        max_tags = get_tagger_config_value("max_tags", 30)

    total = len(image_paths)
    
    # íƒœê·¸ ê²°ê³¼ ìˆ˜ì§‘
    tag_results = []
    
    for i, p in enumerate(image_paths):
        try:
            tags = predict_tags_enhanced(
                self,
                p,
                use_config=use_config,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                apply_sigmoid=apply_sigmoid,
                tta_enabled=tta_enabled,
                tta_horizontal_flip=tta_horizontal_flip,
                tta_merge_mode=tta_merge_mode,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
            tag_results.append(tags)
            self.tag_generated.emit(p, tags)
        except Exception as e:
            self.error_occurred.emit(f"íƒœê·¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            tag_results.append([])  # ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸
        finally:
            self.progress_updated.emit(i + 1, total)
    
    # íƒ€ì„ë¨¸ì‹  ë¡œê·¸ ê¸°ë¡ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    try:
        from timemachine_log import log_ai_batch_tagging
        log_ai_batch_tagging("WD Tagger Enhanced", self.model_id, image_paths, tag_results)
    except Exception:
        pass
    
    self.finished.emit()

# Attach as new methods; do NOT override existing ones
try:
    WdTaggerModel.predict_tags_enhanced = predict_tags_enhanced
    WdTaggerModel.batch_predict_enhanced = batch_predict_enhanced
    print("âœ… WdTaggerModel enhanced methods attached (sigmoid + TTA + JSON toggles).")
except Exception as _e:
    print(f"âš ï¸ Could not attach enhanced methods: {_e}")
# ============================================================================
# End of added enhancement block
# ============================================================================

# ============================================================================
# [ADDED V2] General MCut minimum (floor) + JSON toggles
# - Adds *optional* minimum floor for general MCut.
# - Controlled via models/wd_tagger_config.json:
#     "general_mcut_min_enabled": false,
#     "general_mcut_min": 0.15
# - Non-invasive: no existing functions above are modified.
# - New methods: predict_tags_enhanced_v2 / batch_predict_enhanced_v2
# ============================================================================

import numpy as __np

def _enh_v2_default_config():
    return {
        "general_mcut_min_enabled": False,
        "general_mcut_min": 0.15
    }

def _load_enh_v2_config_with_defaults():
    cfg = {}
    try:
        cfg = load_tagger_config()
    except Exception:
        cfg = {}
    for k, v in _enh_v2_default_config().items():
        cfg.setdefault(k, v)
    return cfg

def upgrade_tagger_config_for_enhancements_v2():
    """
    Idempotently add general MCut floor keys to models/wd_tagger_config.json if missing.
    Preserves existing keys/values.
    """
    try:
        cfg = load_tagger_config()
        changed = False
        for k, v in _enh_v2_default_config().items():
            if k not in cfg:
                cfg[k] = v
                changed = True
        if changed:
            save_tagger_config(cfg)
            print("ğŸ”§ wd_tagger_config.json upgraded with V2 (general MCut min) keys.")
    except Exception as e:
        print(f"âš ï¸ Could not upgrade wd_tagger_config.json (V2): {e}")

try:
    upgrade_tagger_config_for_enhancements_v2()
except Exception:
    pass

def predict_tags_enhanced_v2(
    self,
    image_path: str,
    use_config: bool = True,
    # MCut toggles (if None â†’ read from JSON)
    general_mcut_enabled: bool = None,
    character_mcut_enabled: bool = None,
    # NEW: general MCut minimum controls (if None â†’ read from JSON)
    general_mcut_min_enabled: bool = None,
    general_mcut_min: float = None,
    # Existing enhancement toggles (if present from previous block)
    apply_sigmoid: bool = None,
    tta_enabled: bool = None,
    tta_horizontal_flip: bool = None,
    tta_merge_mode: str = None,
    max_tags: int = None,
    exclude_tags: list = None,
):
    """
    Enhanced V2 prediction:
    - Same as predict_tags_enhanced(...) with *additional* support for
      a minimum floor on the general MCut threshold.
    - If enabled, final general threshold = max(general_mcut_min, mcut_value).
    """
    if not self.is_loaded:
        self.load_model()

    # Load configs
    # Base enhancement config (if present)
    try:
        base_cfg = _load_enh_config_with_defaults() if use_config else _enh_default_config()
    except NameError:
        # If first enhancement block isn't present, fall back to sane defaults
        base_cfg = {
            "general_mcut_enabled": False,
            "character_mcut_enabled": False,
            "apply_sigmoid": False,
            "tta_enabled": False,
            "tta_horizontal_flip": True,
            "tta_merge_mode": "mean"
        }
    # V2 keys
    v2_cfg = _load_enh_v2_config_with_defaults() if use_config else _enh_v2_default_config()

    # Resolve toggles/values
    if general_mcut_enabled is None:
        general_mcut_enabled = bool(base_cfg.get("general_mcut_enabled", False))
    if character_mcut_enabled is None:
        character_mcut_enabled = bool(base_cfg.get("character_mcut_enabled", False))

    if general_mcut_min_enabled is None:
        general_mcut_min_enabled = bool(v2_cfg.get("general_mcut_min_enabled", False))
    if general_mcut_min is None:
        general_mcut_min = float(v2_cfg.get("general_mcut_min", 0.15))

    if apply_sigmoid is None:
        apply_sigmoid = bool(base_cfg.get("apply_sigmoid", False))
    if tta_enabled is None:
        tta_enabled = bool(base_cfg.get("tta_enabled", False))
    if tta_horizontal_flip is None:
        tta_horizontal_flip = bool(base_cfg.get("tta_horizontal_flip", True))
    if tta_merge_mode is None:
        tta_merge_mode = str(base_cfg.get("tta_merge_mode", "mean"))

    if max_tags is None:
        max_tags = get_tagger_config_value("max_tags", 30)

    # Load image
    pil = PILImage.open(image_path)

    # Inference (reuse helpers from first enhancement block if present)
    try:
        scores = _predict_scores_single_pass(self, pil, apply_sigmoid=apply_sigmoid)
        if tta_enabled:
            _scores = [scores]
            if tta_horizontal_flip:
                pil_flip = pil.transpose(PILImage.FLIP_LEFT_RIGHT)
                _scores.append(_predict_scores_single_pass(self, pil_flip, apply_sigmoid=apply_sigmoid))
            scores = __np.mean(__np.stack(_scores, axis=0), axis=0).astype(__np.float32) if tta_merge_mode != "max" else __np.max(__np.stack(_scores, axis=0), axis=0).astype(__np.float32)
    except NameError:
        # If helper not available, do single pass baseline
        tensor = self._prepare_tensor_reference(pil)
        input_name = self.session.get_inputs()[0].name
        out_name = self.session.get_outputs()[0].name
        preds = self.session.run([out_name], {input_name: tensor})[0]
        scores = preds[0].astype(__np.float32)

    labels = list(zip(self.tag_names, scores))

    # rating (not returned; parity only)
    rating_names = [labels[i] for i in self.rating_indexes]
    _ = dict(rating_names)

    # ---- general with MCut + optional floor ----
    general_names = [labels[i] for i in self.general_indexes]
    if general_mcut_enabled and len(general_names) >= 2:
        general_probs = __np.array([x[1] for x in general_names], dtype=__np.float32)
        mcut_val = self._mcut_threshold(general_probs)
        if general_mcut_min_enabled:
            general_thresh = max(float(general_mcut_min), mcut_val)
        else:
            general_thresh = mcut_val
    else:
        general_thresh = self.general_threshold
    general_res = {t: float(s) for (t, s) in general_names if s > general_thresh}

    # ---- character (unchanged from reference/enhanced) ----
    character_names = [labels[i] for i in self.character_indexes]
    if character_mcut_enabled and len(character_names) >= 2:
        character_probs = __np.array([x[1] for x in character_names], dtype=__np.float32)
        character_mcut_min = get_tagger_config_value("character_mcut_min", 0.15)
        character_thresh = max(character_mcut_min, self._mcut_threshold(character_probs))
    else:
        character_thresh = self.character_threshold
    character_res = {t: float(s) for (t, s) in character_names if s > character_thresh}

    ex = set(exclude_tags or [])
    picked = [(t, sc) for (t, sc) in {**general_res, **character_res}.items() if t not in ex]
    picked.sort(key=lambda x: x[1], reverse=True)
    if max_tags > 0:
        picked = picked[:max_tags]
    return picked

def batch_predict_enhanced_v2(
    self,
    image_paths,
    use_config: bool = True,
    general_mcut_enabled: bool = None,
    character_mcut_enabled: bool = None,
    general_mcut_min_enabled: bool = None,
    general_mcut_min: float = None,
    apply_sigmoid: bool = None,
    tta_enabled: bool = None,
    tta_horizontal_flip: bool = None,
    tta_merge_mode: str = None,
    max_tags: int = None,
    exclude_tags=None,
):
    if not self.is_loaded:
        self.load_model()

    if max_tags is None:
        max_tags = get_tagger_config_value("max_tags", 30)

    total = len(image_paths)
    
    # íƒœê·¸ ê²°ê³¼ ìˆ˜ì§‘
    tag_results = []
    
    for i, p in enumerate(image_paths):
        try:
            tags = predict_tags_enhanced_v2(
                self,
                p,
                use_config=use_config,
                general_mcut_enabled=general_mcut_enabled,
                character_mcut_enabled=character_mcut_enabled,
                general_mcut_min_enabled=general_mcut_min_enabled,
                general_mcut_min=general_mcut_min,
                apply_sigmoid=apply_sigmoid,
                tta_enabled=tta_enabled,
                tta_horizontal_flip=tta_horizontal_flip,
                tta_merge_mode=tta_merge_mode,
                max_tags=max_tags,
                exclude_tags=exclude_tags,
            )
            tag_results.append(tags)
            self.tag_generated.emit(p, tags)
        except Exception as e:
            self.error_occurred.emit(f"íƒœê·¸ ì˜ˆì¸¡ ì‹¤íŒ¨(v2): {e}")
            tag_results.append([])  # ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸
        finally:
            self.progress_updated.emit(i + 1, total)
    
    # íƒ€ì„ë¨¸ì‹  ë¡œê·¸ ê¸°ë¡ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    try:
        from timemachine_log import log_ai_batch_tagging
        log_ai_batch_tagging("WD Tagger Enhanced V2", self.model_id, image_paths, tag_results)
    except Exception:
        pass
    
    self.finished.emit()

# Attach V2 methods (without removing previous ones)
try:
    WdTaggerModel.predict_tags_enhanced_v2 = predict_tags_enhanced_v2
    WdTaggerModel.batch_predict_enhanced_v2 = batch_predict_enhanced_v2
    print("âœ… WdTaggerModel V2 methods attached (general MCut min + JSON toggles).")
except Exception as __e:
    print(f"âš ï¸ Could not attach V2 enhanced methods: {__e}")
# ============================================================================
# End of V2 enhancement block
# ============================================================================

# ============================================================================
# WD Download Thread (LLaVAì™€ í†µì¼ëœ ë°©ì‹)
# ============================================================================

class WdDownloadThread(QThread):
    """WD ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ (LLaVAì™€ í†µì¼)"""
    
    progress_updated = Signal(str, int, int, str)  # filename, downloaded, total, status
    download_finished = Signal(bool)  # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
    error_occurred = Signal(str)  # ì˜¤ë¥˜ ë°œìƒ
    
    def __init__(self, model_id: str, use_gpu: bool = True):
        super().__init__()
        self.model_id = model_id
        self.use_gpu = use_gpu
        self.tagger = None
    
    def run(self):
        """ìŠ¤ë ˆë“œì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
        try:
            print(f"[WD Download Thread] ìŠ¤ë ˆë“œ ì‹œì‘: {self.model_id}")
            self.tagger = WdTaggerModel(self.model_id, self.use_gpu)
            
            # ë‹¤ìš´ë¡œë“œ ì§„í–‰ ìƒí™© ì‹œê·¸ë„ ì—°ê²°
            download_progress_emitter.progress_updated.connect(self.progress_updated)
            
            # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            success = self.tagger.download_model_files()
            
            self.download_finished.emit(success)
            
        except Exception as e:
            print(f"[WD Download Thread] ì˜¤ë¥˜: {e}")
            self.error_occurred.emit(str(e))
            self.download_finished.emit(False)
